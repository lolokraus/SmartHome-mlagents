{
    "name": "root",
    "gauges": {
        "HeatingAgent.Policy.Entropy.mean": {
            "value": 0.9355453848838806,
            "min": 0.40633532404899597,
            "max": 2.7723352909088135,
            "count": 2000
        },
        "HeatingAgent.Policy.Entropy.sum": {
            "value": 442.5129699707031,
            "min": 194.82217407226562,
            "max": 1519.2296142578125,
            "count": 2000
        },
        "HeatingAgent.Step.mean": {
            "value": 999956.0,
            "min": 473.0,
            "max": 999956.0,
            "count": 2000
        },
        "HeatingAgent.Step.sum": {
            "value": 999956.0,
            "min": 473.0,
            "max": 999956.0,
            "count": 2000
        },
        "HeatingAgent.Policy.ExtrinsicValueEstimate.mean": {
            "value": 25.240346908569336,
            "min": -0.6597155332565308,
            "max": 33.794490814208984,
            "count": 2000
        },
        "HeatingAgent.Policy.ExtrinsicValueEstimate.sum": {
            "value": 201.9227752685547,
            "min": -6.5971550941467285,
            "max": 288.788818359375,
            "count": 2000
        },
        "HeatingAgent.Environment.EpisodeLength.mean": {
            "value": 472.0,
            "min": 80.5,
            "max": 914.0,
            "count": 1948
        },
        "HeatingAgent.Environment.EpisodeLength.sum": {
            "value": 472.0,
            "min": 241.0,
            "max": 1160.0,
            "count": 1948
        },
        "HeatingAgent.Environment.CumulativeReward.mean": {
            "value": 162.386323928833,
            "min": -5.996215450763702,
            "max": 313.2491782903671,
            "count": 1945
        },
        "HeatingAgent.Environment.CumulativeReward.sum": {
            "value": 162.386323928833,
            "min": -31.035736322402954,
            "max": 427.78176712989807,
            "count": 1945
        },
        "HeatingAgent.Policy.ExtrinsicReward.mean": {
            "value": 162.386323928833,
            "min": -5.996215450763702,
            "max": 313.2491782903671,
            "count": 1945
        },
        "HeatingAgent.Policy.ExtrinsicReward.sum": {
            "value": 162.386323928833,
            "min": -31.035736322402954,
            "max": 427.78176712989807,
            "count": 1945
        },
        "HeatingAgent.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 2000
        },
        "HeatingAgent.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 2000
        },
        "HeatingAgent.Losses.PolicyLoss.mean": {
            "value": 0.0952446383757662,
            "min": 0.08967861555457274,
            "max": 0.10755349376200903,
            "count": 83
        },
        "HeatingAgent.Losses.PolicyLoss.sum": {
            "value": 0.0952446383757662,
            "min": 0.08967861555457274,
            "max": 0.10755349376200903,
            "count": 83
        },
        "HeatingAgent.Losses.ValueLoss.mean": {
            "value": 1.4042869272595602,
            "min": 0.1519517514741782,
            "max": 4.341103703206312,
            "count": 83
        },
        "HeatingAgent.Losses.ValueLoss.sum": {
            "value": 1.4042869272595602,
            "min": 0.1519517514741782,
            "max": 4.341103703206312,
            "count": 83
        },
        "HeatingAgent.Policy.LearningRate.mean": {
            "value": 4.1769986079998467e-07,
            "min": 4.1769986079998467e-07,
            "max": 0.00029639580120140006,
            "count": 83
        },
        "HeatingAgent.Policy.LearningRate.sum": {
            "value": 4.1769986079998467e-07,
            "min": 4.1769986079998467e-07,
            "max": 0.00029639580120140006,
            "count": 83
        },
        "HeatingAgent.Policy.Epsilon.mean": {
            "value": 0.1001392,
            "min": 0.1001392,
            "max": 0.1987986,
            "count": 83
        },
        "HeatingAgent.Policy.Epsilon.sum": {
            "value": 0.1001392,
            "min": 0.1001392,
            "max": 0.1987986,
            "count": 83
        },
        "HeatingAgent.Policy.Beta.mean": {
            "value": 1.0682079999999977e-05,
            "min": 1.0682079999999977e-05,
            "max": 0.00049411314,
            "count": 83
        },
        "HeatingAgent.Policy.Beta.sum": {
            "value": 1.0682079999999977e-05,
            "min": 1.0682079999999977e-05,
            "max": 0.00049411314,
            "count": 83
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1705921767",
        "python_version": "3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:01:18) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\lkraus\\AppData\\Local\\miniconda3\\envs\\mlagents\\Scripts\\mlagents-learn config/heating_control_config.yaml --run-id=HeatingRun212",
        "mlagents_version": "1.1.0.dev0",
        "mlagents_envs_version": "1.1.0.dev0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.13.1+cu117",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1705928299"
    },
    "total": 6532.261986800004,
    "count": 1,
    "self": 0.021556299994699657,
    "children": {
        "run_training.setup": {
            "total": 0.07271810004021972,
            "count": 1,
            "self": 0.07271810004021972
        },
        "TrainerController.start_learning": {
            "total": 6532.167712399969,
            "count": 1,
            "self": 22.598860899335705,
            "children": {
                "TrainerController._reset_env": {
                    "total": 4.5056902000214905,
                    "count": 1,
                    "self": 4.5056902000214905
                },
                "TrainerController.advance": {
                    "total": 6504.953976700548,
                    "count": 1003607,
                    "self": 20.97958831844153,
                    "children": {
                        "env_step": {
                            "total": 5971.748806829564,
                            "count": 1003607,
                            "self": 4276.978314445238,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 1681.1569907859666,
                                    "count": 1003607,
                                    "self": 50.32444718276383,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 1630.8325436032028,
                                            "count": 1000020,
                                            "self": 1630.8325436032028
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 13.613501598360017,
                                    "count": 1003607,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 6501.021761907905,
                                            "count": 1003607,
                                            "is_parallel": true,
                                            "self": 3147.183416443353,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.00037949997931718826,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00022649992024526,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.00015300005907192826,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.00015300005907192826
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 3353.8379659645725,
                                                    "count": 1003607,
                                                    "is_parallel": true,
                                                    "self": 74.51179882802535,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 68.05982741358457,
                                                            "count": 1003607,
                                                            "is_parallel": true,
                                                            "self": 68.05982741358457
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 2983.6495676958584,
                                                            "count": 1003607,
                                                            "is_parallel": true,
                                                            "self": 2983.6495676958584
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 227.61677202710416,
                                                            "count": 1003607,
                                                            "is_parallel": true,
                                                            "self": 143.336744582979,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 84.28002744412515,
                                                                    "count": 2007214,
                                                                    "is_parallel": true,
                                                                    "self": 84.28002744412515
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 512.2255815525423,
                            "count": 1003607,
                            "self": 27.108780078822747,
                            "children": {
                                "process_trajectory": {
                                    "total": 79.08469517389312,
                                    "count": 1003607,
                                    "self": 78.89271837391425,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.19197679997887462,
                                            "count": 2,
                                            "self": 0.19197679997887462
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 406.0321062998264,
                                    "count": 83,
                                    "self": 130.15050329914084,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 275.8816030006856,
                                            "count": 46692,
                                            "self": 275.8816030006856
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 1.200009137392044e-06,
                    "count": 1,
                    "self": 1.200009137392044e-06
                },
                "TrainerController._save_models": {
                    "total": 0.10918340005446225,
                    "count": 1,
                    "self": 0.00159580004401505,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.1075876000104472,
                            "count": 1,
                            "self": 0.1075876000104472
                        }
                    }
                }
            }
        }
    }
}